<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Journy of Mind - Stay Foolish, Stay Hungry</title>

    <!-- Bootstrap core CSS -->
    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="../vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="../css/clean-blog.min.css" rel="stylesheet">

  </head>

  <body>

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand" href="../index.html">J.J. Young</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link" href="../index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="../about.html">About</a>
            </li>
<!--             <li class="nav-item">
              <a class="nav-link" href="ig.html">Information Geometry</a>
            </li> -->
            <li class="nav-item">
              <a class="nav-link" href="../contact.html">Contact</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Header -->
    <header class="masthead" style="background-image: url('../img/post-bg.jpg')">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <div class="post-heading">
              <h1>Build a data processing pipeline from scratch</h1>
              <h2 class="subheading">Within 100 lines of code using Pandas</h2>
              <span class="meta">Posted by
                <a href="#">J.J. Young</a>
                on Jan 8, 2017</span>
            </div>
          </div>
        </div>
      </div>
    </header>

    <!-- Post Content -->
    <article>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <p>To build a data processing pipeline, we need to answer the following problem:</p>

            <p>
              <ul>
                <li>First, what is the format of the data?</li>
                <li>Second, what operation will be performed on the data?</li>
                <li>Thirdly, what is pipeline and how to excute a pipeline?</li>
                <li>At last, how to scale to large dataset?</li>
              </ul>
            </p>

            <p>For the first question, we will always assume that the data to be processed is in table-like format. In the early stage of machine learning applications, data proceesing can always be categried into two types. <br>One is extract feature columns from existed feature columns, the other is doing aggregatition on existed feature columns based on certain metrics. All in all, these two are column-based. The data processing framework should support column excuation. <br>Data pipeline is a seqence of transformation function excuting on the data, the previous excuter's output is the successive's input.<br>For the last question, we can mimic MapReduce to processing the data in a data parallel style with multiprocessing.</p>

            <h2 class="section-heading">Pandas - a Short Introduction</h2>
            <p>Here we will use pandas to process our data. In a enterprise, we usually deal a lot with json data. First let us start to generate some sample data:</p>
<pre><code class="language-python">data = [{'state': 'Florida',
         'shortname': 'FL',
         'info': {
             'governor': 'Rick Scott'
         },
         'counties': [{'name': 'Dade', 'population': 12345},
                      {'name': 'Broward', 'population': 40000},
                      {'name': 'Palm Beach', 'population': 60000}]},
        {'state': 'Ohio',
         'shortname': 'OH',
         'info': {
             'governor': 'John Kasich'
         },
         'counties': [{'name': 'Summit', 'population': 1234},
                      {'name': 'Cuyahoga', 'population': 1337}]}]
from pandas.io.json import json_normalize

df = json_normalize(data, 'counties', ['state', 'shortname',
                                           ['info', 'governor']])
</code></pre>

            <p>To update the columns of the Pandas. Either ways are equivalent.</p>

<pre><code class="language-python">df['some_new_col1'] = df['state'].map(lambda e: e)

df['some_new_col2'] = df.apply(lambda e: e['state'])
</code></pre>

            <p>Sometimes the new features may be depended on serveral other columns.</p>

<pre><code class="language-python">df['some_new_col3'] = df[['state', 'name']].map(lambda e: " ".join(e))
</code></pre>

            <h2 class="section-heading">Processing Data in Pipeline Style</h2>

            <p>In traditional machine applications such as face recognition have different steps. First apply face calibration methods, then extract the features and then train the classifiers. Finally release into production usage. These can be viewed as the sequence of transformation over the faces data.</p>

            <p>Express this in a abstract way, this can be viewed as the following.</p>
<pre><code class="language-python">f(g(h(df), arg1=a), arg2=b, arg3=c)
</code></pre>

            <p>But it looks rather awkward, thanks to Pandas built-in pipe method, we can simply write code as following.</p>
<pre><code class="language-python">df.pipe(h) \
  .pipe(g, arg1=a) \
  .pipe(f, arg2=b, arg3=c)
</code></pre>

            <p>The f, g, h refered above can be functions, lambda expression or even class. In a lot of application I developed, I am in favor of class. Because it can offer more flexibility in controlling the behavior of the operators in the pipeline. But how can a class work like a function? That is Simple, use the Python magic function.</p>

<pre><code class="language-python">class SomeMagicFunction: \
      def __init__(self, *args, **kwargs):
            self.args = args
            self.kwargs = kwargs

      def __call__(self, *args, **kwargs):
            print("do some thing magic with {} and {}".format(self.args, self.kwargs))
</code></pre>

            <p>A more realistic one is like the following.</p>
 <pre><code class="language-python">df.pipe(DimensionReduction('iso', to_col='dimension_reduced'), conf=conf, status=status) \
  .pipe(RiskScoreCalculator("knn", from_col='dimension_reduced', to_col='abnormal_score'), conf=conf, status=status) \
  .pipe(NormalizeAbnormalScore(from_col='abnormal_score', to_col='abnormal_score_normalize'), conf=conf, status=status) \
  .pipe(UpdateLabel(0), conf=conf, status=status) \
  .pipe(UpdateDescription(0), conf=conf, status=status) \
  .pipe(UpdateToRedis(start_time, end_time), conf=conf, status=status) \
  .pipe(UpdateImportance(data_manager.current_batch_json), conf=conf, status=status) \
  .pipe(UpdateToES(data_manager.current_batch_json), conf=conf, status=status)
</code></pre>           
            <p>DimensionReduction, RiskScoreCalculator, NormalizeAbnormalScore, UpdateLabel, UpdateDescription will apply new columns to the dataframe according to its own function. UpdateToRedis, UpdateImportance, UpdateToES will update the enriched result into databases for downstream systems to process the data. The conf and status is dictionary value in python. We assume that conf should never be applied with write methods, and each operator in the pipeline can only write small amount of data in status as a message queue. This actually uses Python dictionary side effect(dictionary is passed by reference not value) and should be taken carefully.</p>

            <h2 class="section-heading">Scale to Large Dataset</h2>

            <p>At last, we nearly come to the end of pipeline processing. Still if the dataset is large, how can we deal with it? I guess someone experienced will say <a href="https://github.com/dask/dask/">Dask</a> is what you neeed. Actually, we can still use Pandas but in a parallel manner.</p>

            <p>Parallel computing can be categorised into three kinds: data parallel, task parallel and mixed mode.
            For processing the dataframe, it is obvious that data parallel should be easy. By applying MapReduce methodology, data can be chunked into pieces and processed seperatedly and combine these together. We only need to implement column based enrichment operation and parallel aggregate. These are mostly needed.</p>

 <pre><code class="language-python">import multiprocessing as mp

def parallel_runner(fn, *args, **kwargs):
    data = args[0]
    data_chunks = split_strategy(data)(data)
    with mp.Pool() as pool:
        results = pool.starmap(partial(fn, **kwargs),
                               ((i,) + args[1:] for i in data_chunks))
    return pd.concat(results).reset_index(drop=True)
</code></pre>  

            <p>The split_strategy is ignored here. It can be customised with fixed size of fixed chunk count etc. partial function is used here, acting as some kind of trick, as the starmap does not support kwargs. The first argument in the args is supposed to be the dataframe to be processed. And the parallel aggregatition is as following, the reader should not be much supprised:</p>

 <pre><code class="language-python">def parallel_aggregate(dfGrouped, func):
    with mp.Pool() as pool:
        ret_list = pool.starmap(func, ((name, group) for name, group in dfGrouped))
    return pd.concat(ret_list)
</code></pre>  

            <p>Hopefully, from this blog, data pipeline designing is cleard and simplified with Pandas.</p>

          </div>
        </div>
      </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <ul class="list-inline text-center">
              <li class="list-inline-item">
                <a href="#">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="#">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="#">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
            </ul>
            <p class="copyright text-muted">Copyright &copy; Detectivebag 2017</p>
          </div>
        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="../vendor/jquery/jquery.min.js"></script>
    <script src="../vendor/popper/popper.min.js"></script>
    <script src="../vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="../js/clean-blog.min.js"></script>

  </body>

</html>
